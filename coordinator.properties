#JobTracker and NodeName
namenode=hdfs://nc9128110007.kraklab.pl.ibm.com:8020
jobtracker=nc9128110007.kraklab.pl.ibm.com:8050
#prefix of the HDFS path for input and output, adapt!
PREFIX=${namenode}/user
#HDFS path where you need to copy workflow.xml and lib/*.jar to
oozie.use.system.libpath=true
#one of the values from Hadoop mapred.queue.names
user.name=sb
queueName=default
oozie.use.system.libpath=true
oozie.libpath=/user/oozie/share/lib/lib_20170405230852
oozie.action.sharelib.for.sqoop=hive,hcatalog,sqoop,hive2

prescript=preparelast.sh
prescriptPath=${oozie.wf.application.path}/${prescript}

echoscript=echoscript.sh
echoscriptPath=${oozie.wf.application.path}/${echoscript}

P_TABLE=customers
P_ID=customerNumber
P_DATABASE=salesdb
P_URL=jdbc:hive2://nc9128110007.kraklab.pl.ibm.com:10000/

P_HIVE_KERBEROS=hive/nc9128110007.kraklab.pl.ibm.com@SB.COM
P_METASTORE_KERBEROS=hive/nc9128109010.kraklab.pl.ibm.com@SB.COM

P_METASTORE=thrift://nc9128109010.kraklab.pl.ibm.com:9083

S_URL=jdbc:mysql://re64/classicmodels
S_USER=test
S_PASSWORD=test
S_DRIVER=com.mysql.jdbc.Driver
S_STAGETABLE=stagedb.customers

HIVE_CREATESCRIPT=${oozie.wf.application.path}/creates.sql
HIVE_UPDATESCRIPT=${oozie.wf.application.path}/updates.sql

K_PRINC=sb@SB.COM
K_PASSWORD=secret
oozie.coord.application.path=${PREFIX}/${user.name}/loadhive
apppath=${oozie.coord.application.path}
